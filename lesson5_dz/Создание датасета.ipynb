{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальный датасет довольно избыточный, поэтому для проведения задания мы пользуемся этим ноутбуком, чтобы взять только нужную часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачать весь датасет (~5 Гб) можно по этой ссылке: https://drive.google.com/file/d/1CUZnBtYwifVXS21yVg62T-vrPVayso5H/view\n",
    "Файл с отсутствующими скелетами: https://github.com/shahroudy/NTURGB-D/blob/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt (т.е. список файлов из большого датасета, в которых отсутсвуют скелеты и мы эти файлы будем игнорировать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"nturgbd_skeletons_s001_to_s017/\"\r\n",
    "data_path = \"nturgbd_skeletons_s001_to_s017/nturgb+d_skeletons/\"\r\n",
    "\r\n",
    "#### список отсутсвующих элементов так же будет доступен \r\n",
    "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = list(range(0, 28)) #количество людей выполняющих действия\r\n",
    "training_classes = [3, 7, 24, 38, 27, 32, 68, 55] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\r\n",
    "training_cameras = [1, 2, 3] \r\n",
    "\r\n",
    "num_joint = 25\r\n",
    "max_frame = 300 # Длина отрезка которую мы вычленяем из большого датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть функция, которая позволяет нам считать данные для каждого класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path, broken_files_path):\r\n",
    "    labels = []\r\n",
    "    files = []\r\n",
    "    action_classes = {}\r\n",
    "    counter = 0\r\n",
    "    files_counter = {}\r\n",
    "\r\n",
    "    with open(broken_files_path, 'r') as f:\r\n",
    "        broken_files = f.read().split(\"\\n\")\r\n",
    "\r\n",
    "    raw_files = os.listdir(data_path)\r\n",
    "    num_frames = 0\r\n",
    "\r\n",
    "    for filename in raw_files:\r\n",
    "        # if filename.strip('.skeleton') in broken_files:\r\n",
    "        # if filename in broken_files:\r\n",
    "        #     print('hello')\r\n",
    "        # print(filename.strip('.skeleton'))\r\n",
    "        if filename.strip('.skeleton') not in broken_files:\r\n",
    "            action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\r\n",
    "            subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\r\n",
    "            camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\r\n",
    "            if action_class in training_classes and camera_id in training_cameras:  #and subject_id in training_subjects:\r\n",
    "                if action_class in action_classes:\r\n",
    "                    if files_counter[action_class] < 120:\r\n",
    "                        files.append([filename,action_classes[action_class]])\r\n",
    "                        files_counter[action_class] = files_counter[action_class] + 1\r\n",
    "                else:\r\n",
    "                    action_classes.update({action_class : counter})\r\n",
    "                    files_counter.update({action_class : 1})\r\n",
    "                    counter+=1\r\n",
    "                    files.append([filename,action_classes[action_class]])\r\n",
    "#                     labels.append([action_class])\r\n",
    "    print(\"action classes: \", action_classes)\r\n",
    "    print(\"action files: \", files_counter)\r\n",
    "    \r\n",
    "    return files, action_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция фильтр для того, что бы найти только координаты x,y,z(т.к. в датасете\r\n",
    "# хранится на порядок больше информации, нежели только координаты x,y,z)\r\n",
    "# (Остальные данные нам и не нужны, т.к. у нас нет ик-камер)\r\n",
    "def read_skeleton_filter(file):\r\n",
    "    with open(file, 'r') as f:\r\n",
    "        skeleton_sequence = {}\r\n",
    "        skeleton_sequence['numFrame'] = int(f.readline())\r\n",
    "        skeleton_sequence['frameInfo'] = []\r\n",
    "        for t in range(skeleton_sequence['numFrame']):\r\n",
    "            frame_info = {}\r\n",
    "            frame_info['numBody'] = int(f.readline())\r\n",
    "            frame_info['bodyInfo'] = []\r\n",
    "\r\n",
    "            for m in range(frame_info['numBody']):\r\n",
    "                body_info = {}\r\n",
    "                body_info_key = [\r\n",
    "                    'bodyID', 'clipedEdges', 'handLeftConfidence',\r\n",
    "                    'handLeftState', 'handRightConfidence', 'handRightState',\r\n",
    "                    'isResticted', 'leanX', 'leanY', 'trackingState'\r\n",
    "                ]\r\n",
    "                body_info = {\r\n",
    "                    k: float(v)\r\n",
    "                    for k, v in zip(body_info_key, f.readline().split())\r\n",
    "                }\r\n",
    "                body_info['numJoint'] = int(f.readline())\r\n",
    "                body_info['jointInfo'] = []\r\n",
    "                for v in range(body_info['numJoint']):\r\n",
    "                    joint_info_key = [\r\n",
    "                        'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\r\n",
    "                        'orientationW', 'orientationX', 'orientationY',\r\n",
    "                        'orientationZ', 'trackingState'\r\n",
    "                    ]\r\n",
    "                    joint_info = {\r\n",
    "                        k: float(v)\r\n",
    "                        for k, v in zip(joint_info_key, f.readline().split())\r\n",
    "                    }\r\n",
    "                    body_info['jointInfo'].append(joint_info)\r\n",
    "                frame_info['bodyInfo'].append(body_info)\r\n",
    "            skeleton_sequence['frameInfo'].append(frame_info)\r\n",
    "\r\n",
    "    return skeleton_sequence\r\n",
    "\r\n",
    "# Здесь мы используем нашу функцию фильр и оформляем дату в x,y,z-cкоординаты\r\n",
    "def read_xyz(file, max_body=1, num_joint=25):\r\n",
    "    seq_info = read_skeleton_filter(file)\r\n",
    "    data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\r\n",
    "    for n, f in enumerate(seq_info['frameInfo']):\r\n",
    "        for m, b in enumerate(f['bodyInfo']):\r\n",
    "            for j, v in enumerate(b['jointInfo']):\r\n",
    "                if m < max_body and j < num_joint:\r\n",
    "                    data[m, n, j, :] = [v['x'], v['y'], v['z']]\r\n",
    "\r\n",
    "                else:\r\n",
    "                    pass\r\n",
    "\r\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В этой функции меняем количество фреймов подаваемых на вход модели\n",
    "\n",
    "В задании нужно пронаблюдать зависимость качества обучения модели от количества кадров, которые мы подаем в модель. Т.е. то, сколько кадров у нас отведено на один блок. В ноутбуке мы обучали модель на 45 кадрах. Вам предлагается посмотреть в меньшую или большую сторону.\n",
    "\n",
    "По хорошему функцию ниже нужно прописать внутри определения датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coords_blocks(test_file, chonk_len = 45):   \r\n",
    "    frame_counter = 0\r\n",
    "    new_labels = []\r\n",
    "    new_frames = []\r\n",
    "    blocks = []\r\n",
    "    \r\n",
    "    test_frames = read_xyz(data_path + test_file[0])[0]\r\n",
    "    label = test_file[1]\r\n",
    "    slice_len = chonk_len * int(len(test_frames)/chonk_len)\r\n",
    "\r\n",
    "\r\n",
    "    for index in range(len(test_frames[:slice_len])):\r\n",
    "        frame_counter += 1\r\n",
    "        new_frames.append(test_frames[index].flatten())\r\n",
    "        if frame_counter == chonk_len:\r\n",
    "            frame_counter = 0\r\n",
    "            blocks.append(np.array(new_frames))\r\n",
    "            new_labels = new_labels + [label]\r\n",
    "            new_frames = []\r\n",
    "       \r\n",
    "            \r\n",
    "    return blocks, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action classes:  {3: 0, 7: 1, 24: 2, 27: 3, 32: 4, 38: 5, 55: 6}\n",
      "action files:  {3: 120, 7: 120, 24: 120, 27: 120, 32: 120, 38: 120, 55: 120}\n"
     ]
    }
   ],
   "source": [
    "##### список файлов с лейблами на каждый файл \n",
    "working_files_with_labels, action_classes = read_data(data_path, broken_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NTU_RGBD_samples_with_missing_skeletons.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {v: k for k, v in action_classes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Здесь выносится сгенерированный список лейблов с номером класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3, 1: 7, 2: 24, 3: 27, 4: 32, 5: 38, 6: 55}\n"
     ]
    }
   ],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(working_files_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "from  tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6b9adc6d114887be9b8e6cf9d5d101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\r\n",
    "labels = []\r\n",
    "##########################################################################\r\n",
    "numbers = {x: 0 for x in range(len(action_classes))} #####\r\n",
    "##################################################################\r\n",
    "for file in tqdm(working_files_with_labels):\r\n",
    "    frames_blocks, label = create_coords_blocks(file)\r\n",
    "    if label != [] and numbers[label[0]] <= 150:\r\n",
    "        numbers[label[0]] = numbers[label[0]] + len(label)\r\n",
    "        data = data + frames_blocks\r\n",
    "        labels = labels + label\r\n",
    "data_np = np.asarray(data)\r\n",
    "labels_np = np.asarray(labels)\r\n",
    "\r\n",
    "data_sq = data_np.reshape(len(data_np), -1)\r\n",
    "test_data = pd.DataFrame(data_sq)\r\n",
    "test_labels = pd.DataFrame(labels_np)\r\n",
    "test_data['labels'] = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш итоговый файл для загрузки на колаб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"skeletons_classes_1_30.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dc16db89c7b7868c1bda26003793495fc53e348f30248cc96f0b4588f8ccbba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}